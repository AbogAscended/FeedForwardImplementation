{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-28T21:20:32.679412Z",
     "start_time": "2024-06-28T21:20:32.069648Z"
    }
   },
   "source": [
    "#Importing all the different python modules needed\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from ffModel import FeedForward"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T21:20:33.192329Z",
     "start_time": "2024-06-28T21:20:33.181738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#importing data into pandas data frame then separating the test values and input values, then finally using the DataLoader to set it up.\n",
    "trainData = pd.read_csv('train.csv')\n",
    "testValues = trainData.loc[:, 'target']\n",
    "testValuesNum = testValues.to_numpy()\n",
    "testValuesD = torch.tensor(testValuesNum, dtype=torch.float32)\n",
    "columns = trainData.columns\n",
    "columns = columns[columns != 'target']\n",
    "trainValues = trainData.loc[:, columns]\n",
    "trainValues = trainValues.drop(columns = 'id', axis=1)\n",
    "trainValuesNum = trainValues.to_numpy()\n",
    "trainValuesD = torch.tensor(trainValuesNum, dtype=torch.float32)\n",
    "trainingData = DataLoader(TensorDataset(trainValuesD, testValuesD), batch_size=25, shuffle=True)"
   ],
   "id": "6bf0ffa3b56b1648",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T21:20:34.919149Z",
     "start_time": "2024-06-28T21:20:34.506883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "Now its time to set up the model, optimizer, and the loss function to actually preform the training.\n",
    "For the loss equation as im doing uni-variate normal regression to determine the correct numerical value based on 8 input values.\n",
    "I will at first use default hyperparameters and assess how well the model is doing then adjust from there.\n",
    "'''\n",
    "model = FeedForward().to('cuda')\n",
    "optimizer = optim.Adam(model.parameters(), weight_decay= .8)\n",
    "loss = nn.MSELoss()"
   ],
   "id": "369a30afb467ad28",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T21:20:35.395694Z",
     "start_time": "2024-06-28T21:20:35.392863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "Now I will implement a modular training loop\n",
    "'''\n",
    "def trainLoop(dataloader, model, lossf, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        x = x.to('cuda')\n",
    "        y = y.to('cuda')\n",
    "        y = y.view(-1, 1)\n",
    "\n",
    "        # Forward pass through NN\n",
    "        prediction = model(x)\n",
    "        loss = lossf(prediction, y)\n",
    "\n",
    "        # Backwards pass through NN\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 1 == 0:\n",
    "            loss_value = loss.item()\n",
    "            current = batch * dataloader.batch_size + len(x)\n",
    "            print(f\"Batch: {batch}, Batch Size: {len(x)}\")\n",
    "            print(f\"Loss: {loss_value:>7f} [{current}/{size}]\")"
   ],
   "id": "89a68e32e05b9133",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T21:20:36.591923Z",
     "start_time": "2024-06-28T21:20:36.589353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_loop(dataloader, model, lossf):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to('cuda')\n",
    "            y = y.to('cuda')\n",
    "            y = y.view(-1, 1)\n",
    "            pred = model(X)\n",
    "            total_loss += lossf(pred, y).item() * X.size(0)\n",
    "\n",
    "    avg_loss = total_loss / size\n",
    "    print(f\"Test Error: \\n Avg loss: {avg_loss:>8f} \\n\")"
   ],
   "id": "8d89331bc4013f58",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T21:20:37.564043Z",
     "start_time": "2024-06-28T21:20:37.469898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Now to actually train the model in 10 epochs\n",
    "for epoch in range(4):\n",
    "    print(f'Epoch {epoch + 1}\\n ------------------------------------------------')\n",
    "    trainLoop(trainingData, model, loss, optimizer)\n",
    "    test_loop(trainingData, model, loss)\n",
    "print('Done!')"
   ],
   "id": "e2db33157a8a132d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      " ------------------------------------------------\n",
      "Batch: 0, Batch Size: 25\n",
      "Loss: 0.246329 [25/250]\n",
      "Batch: 1, Batch Size: 25\n",
      "Loss: 0.213598 [50/250]\n",
      "Batch: 2, Batch Size: 25\n",
      "Loss: 0.142232 [75/250]\n",
      "Batch: 3, Batch Size: 25\n",
      "Loss: 0.262342 [100/250]\n",
      "Batch: 4, Batch Size: 25\n",
      "Loss: 0.217651 [125/250]\n",
      "Batch: 5, Batch Size: 25\n",
      "Loss: 0.257376 [150/250]\n",
      "Batch: 6, Batch Size: 25\n",
      "Loss: 0.113897 [175/250]\n",
      "Batch: 7, Batch Size: 25\n",
      "Loss: 0.226313 [200/250]\n",
      "Batch: 8, Batch Size: 25\n",
      "Loss: 0.287464 [225/250]\n",
      "Batch: 9, Batch Size: 25\n",
      "Loss: 0.373576 [250/250]\n",
      "Test Error: \n",
      " Avg loss: 0.224622 \n",
      "\n",
      "Epoch 2\n",
      " ------------------------------------------------\n",
      "Batch: 0, Batch Size: 25\n",
      "Loss: 0.223991 [25/250]\n",
      "Batch: 1, Batch Size: 25\n",
      "Loss: 0.134033 [50/250]\n",
      "Batch: 2, Batch Size: 25\n",
      "Loss: 0.204372 [75/250]\n",
      "Batch: 3, Batch Size: 25\n",
      "Loss: 0.300587 [100/250]\n",
      "Batch: 4, Batch Size: 25\n",
      "Loss: 0.229082 [125/250]\n",
      "Batch: 5, Batch Size: 25\n",
      "Loss: 0.333281 [150/250]\n",
      "Batch: 6, Batch Size: 25\n",
      "Loss: 0.267397 [175/250]\n",
      "Batch: 7, Batch Size: 25\n",
      "Loss: 0.194882 [200/250]\n",
      "Batch: 8, Batch Size: 25\n",
      "Loss: 0.136044 [225/250]\n",
      "Batch: 9, Batch Size: 25\n",
      "Loss: 0.208651 [250/250]\n",
      "Test Error: \n",
      " Avg loss: 0.218901 \n",
      "\n",
      "Epoch 3\n",
      " ------------------------------------------------\n",
      "Batch: 0, Batch Size: 25\n",
      "Loss: 0.255370 [25/250]\n",
      "Batch: 1, Batch Size: 25\n",
      "Loss: 0.264607 [50/250]\n",
      "Batch: 2, Batch Size: 25\n",
      "Loss: 0.219321 [75/250]\n",
      "Batch: 3, Batch Size: 25\n",
      "Loss: 0.285415 [100/250]\n",
      "Batch: 4, Batch Size: 25\n",
      "Loss: 0.198276 [125/250]\n",
      "Batch: 5, Batch Size: 25\n",
      "Loss: 0.170456 [150/250]\n",
      "Batch: 6, Batch Size: 25\n",
      "Loss: 0.267800 [175/250]\n",
      "Batch: 7, Batch Size: 25\n",
      "Loss: 0.235562 [200/250]\n",
      "Batch: 8, Batch Size: 25\n",
      "Loss: 0.165658 [225/250]\n",
      "Batch: 9, Batch Size: 25\n",
      "Loss: 0.140412 [250/250]\n",
      "Test Error: \n",
      " Avg loss: 0.220184 \n",
      "\n",
      "Epoch 4\n",
      " ------------------------------------------------\n",
      "Batch: 0, Batch Size: 25\n",
      "Loss: 0.232491 [25/250]\n",
      "Batch: 1, Batch Size: 25\n",
      "Loss: 0.262330 [50/250]\n",
      "Batch: 2, Batch Size: 25\n",
      "Loss: 0.291132 [75/250]\n",
      "Batch: 3, Batch Size: 25\n",
      "Loss: 0.163413 [100/250]\n",
      "Batch: 4, Batch Size: 25\n",
      "Loss: 0.164830 [125/250]\n",
      "Batch: 5, Batch Size: 25\n",
      "Loss: 0.138019 [150/250]\n",
      "Batch: 6, Batch Size: 25\n",
      "Loss: 0.136071 [175/250]\n",
      "Batch: 7, Batch Size: 25\n",
      "Loss: 0.298740 [200/250]\n",
      "Batch: 8, Batch Size: 25\n",
      "Loss: 0.298321 [225/250]\n",
      "Batch: 9, Batch Size: 25\n",
      "Loss: 0.239912 [250/250]\n",
      "Test Error: \n",
      " Avg loss: 0.223008 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T21:20:40.477931Z",
     "start_time": "2024-06-28T21:20:38.367721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#now to set up the testing to submit to kaggle.\n",
    "testData = pd.read_csv('test.csv')\n",
    "savedID = testData.loc[:, 'id']\n",
    "testDataD = testData.drop(columns = 'id')\n",
    "testDataD = testDataD.to_numpy()\n",
    "testDataD = torch.tensor(testDataD, dtype=torch.float32)\n",
    "testValuesFinal = DataLoader(TensorDataset(testDataD), shuffle=False)\n",
    "model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for item in testValuesFinal:\n",
    "        item = item[0].to('cuda')\n",
    "        prediction = model.forward(item)\n",
    "        predictions.append(prediction.cpu().numpy())\n",
    "submission = np.concatenate(predictions).reshape(-1, 1)\n",
    "submission = pd.DataFrame(submission, columns=['target'])\n",
    "final = pd.concat([savedID, submission], axis=1)\n",
    "final.to_csv('submission.csv', index=False)"
   ],
   "id": "c7b5d1c798aa032",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ad91bda7f480f67b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
